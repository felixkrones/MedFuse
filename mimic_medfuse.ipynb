{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb92a66",
   "metadata": {},
   "source": [
    "# Run for our experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b351d316",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be77452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd mimic4extract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate one directory per `SUBJECT_ID`\n",
    "python -m mimic3benchmark.scripts.extract_subjects_iv /data/wolf6245/src/mm_study/data/a_raw/MIMIC/MIMIC-IV data/root/ --filter_subject_id_file \"/data/wolf6245/src/mm_study/data/f_modelling/03_model_input/data-2024-12-19-01-23-23/(3) Chronic ischaemic heart disease/y_fusion_label_not_gt.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf15c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix some issues\n",
    "python -m mimic3benchmark.scripts.validate_events data/root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19164478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breaks up per-subject data into separate episodes\n",
    "python -m mimic3benchmark.scripts.extract_episodes_from_subjects data/root/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d73068",
   "metadata": {},
   "source": [
    "## SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "python -m mimic3benchmark.scripts.split_train_and_test data/root/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate task-specific datasets\n",
    "python -m mimic3benchmark.scripts.create_phenotyping data/root/ data/phenotyping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab26f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split again for validation\n",
    "python -m mimic3models.split_train_val data/phenotyping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351a0cac",
   "metadata": {},
   "source": [
    "## Update labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "807fda92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder_listfile_path = \"/data/wolf6245/src/MedFuse/mimic4extract/data/phenotyping/train/listfile.csv\"\n",
    "test_folder_listfile_path = \"/data/wolf6245/src/MedFuse/mimic4extract/data/phenotyping/test/listfile.csv\"\n",
    "train_listfile_path = \"/data/wolf6245/src/MedFuse/mimic4extract/data/phenotyping/train_listfile.csv\"\n",
    "test_listfile_path = \"/data/wolf6245/src/MedFuse/mimic4extract/data/phenotyping/test_listfile.csv\"\n",
    "val_listfile_path = \"/data/wolf6245/src/MedFuse/mimic4extract/data/phenotyping/val_listfile.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e7c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_label shape before merge: (5280, 12), after merge: (6148, 13)\n",
      "train_folder_listfile shape before dropna: (3704, 9), after dropna: (3704, 9)\n",
      "test_folder_listfile shape before dropna: (842, 9), after dropna: (842, 9)\n",
      "train_listfile shape before dropna: (3394, 9), after dropna: (3394, 9)\n",
      "test_listfile shape before dropna: (842, 9), after dropna: (842, 9)\n",
      "val_listfile shape before dropna: (310, 9), after dropna: (310, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load all dataframes\n",
    "y_file_path = \"/data/wolf6245/src/mm_study/data/f_modelling/03_model_input/data-2024-12-19-01-23-23/(3) Chronic ischaemic heart disease/y_fusion_label_not_gt.parquet\"\n",
    "icu_stay_df = pd.read_csv(\"/data/wolf6245/src/mm_study/data/a_raw/MIMIC/MIMIC-IV/icu/icustays.csv.gz\")\n",
    "key_columns = [\"stay\", \"period_length\", \"stay_id\"]\n",
    "train_folder_listfile = pd.read_csv(train_folder_listfile_path, usecols=key_columns)\n",
    "test_folder_listfile = pd.read_csv(test_folder_listfile_path, usecols=key_columns)\n",
    "train_listfile = pd.read_csv(train_listfile_path, usecols=key_columns)\n",
    "test_listfile = pd.read_csv(test_listfile_path, usecols=key_columns)\n",
    "val_listfile = pd.read_csv(val_listfile_path, usecols=key_columns)\n",
    "df_label = pd.read_parquet(y_file_path)\n",
    "assert list(train_folder_listfile.columns) == list(test_folder_listfile.columns)\n",
    "assert list(train_folder_listfile.columns) == list(train_listfile.columns)\n",
    "assert list(train_folder_listfile.columns) == list(test_listfile.columns)\n",
    "assert list(train_folder_listfile.columns) == list(val_listfile.columns)\n",
    "\n",
    "# Merge stay_ids to df_label from icu_stay_df\n",
    "df_label_shape_old = df_label.shape\n",
    "df_label = df_label.merge(icu_stay_df[[\"subject_id\", \"hadm_id\", \"stay_id\"]], on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "print(f\"df_label shape before merge: {df_label_shape_old}, after merge: {df_label.shape}\")\n",
    "#df_label_columns_to_keep = [c for c in df_label.columns if c not in [\"hadm_id\", \"subject_id\"]]\n",
    "df_label_columns_to_keep = [\"stay_id\", \"(1) Hypertensive diseases\",\n",
    "    \"(2) Ischaemic heart diseases\",\n",
    "    \"(3) Chronic ischaemic heart disease\",\n",
    "    \"(4) Cardiomyopathies diseases\",\n",
    "    \"(5) Dysrhythmias diseases\",\n",
    "    \"(6) Heart failure\",\n",
    "]\n",
    "\n",
    "# Merge labels to all dataframes\n",
    "train_folder_listfile = train_folder_listfile.merge(df_label[df_label_columns_to_keep], on=[\"stay_id\"], how=\"left\")\n",
    "test_folder_listfile = test_folder_listfile.merge(df_label[df_label_columns_to_keep], on=[\"stay_id\"], how=\"left\")\n",
    "train_listfile = train_listfile.merge(df_label[df_label_columns_to_keep], on=[\"stay_id\"], how=\"left\")\n",
    "test_listfile = test_listfile.merge(df_label[df_label_columns_to_keep], on=[\"stay_id\"], how=\"left\")\n",
    "val_listfile = val_listfile.merge(df_label[df_label_columns_to_keep], on=[\"stay_id\"], how=\"left\")\n",
    "\n",
    "# Drop nans\n",
    "train_folder_listfile_shape_old = train_folder_listfile.shape\n",
    "train_folder_listfile = train_folder_listfile.dropna()\n",
    "print(f\"train_folder_listfile shape before dropna: {train_folder_listfile_shape_old}, after dropna: {train_folder_listfile.shape}\")\n",
    "test_folder_listfile_shape_old = test_folder_listfile.shape\n",
    "test_folder_listfile = test_folder_listfile.dropna()\n",
    "print(f\"test_folder_listfile shape before dropna: {test_folder_listfile_shape_old}, after dropna: {test_folder_listfile.shape}\")\n",
    "train_listfile_shape_old = train_listfile.shape\n",
    "train_listfile = train_listfile.dropna()\n",
    "print(f\"train_listfile shape before dropna: {train_listfile_shape_old}, after dropna: {train_listfile.shape}\")\n",
    "test_listfile_shape_old = test_listfile.shape\n",
    "test_listfile = test_listfile.dropna()\n",
    "print(f\"test_listfile shape before dropna: {test_listfile_shape_old}, after dropna: {test_listfile.shape}\")\n",
    "val_listfile_shape_old = val_listfile.shape\n",
    "val_listfile = val_listfile.dropna()\n",
    "print(f\"val_listfile shape before dropna: {val_listfile_shape_old}, after dropna: {val_listfile.shape}\")\n",
    "\n",
    "# Convert label columns to int\n",
    "for col in df_label_columns_to_keep:\n",
    "    if col not in [\"stay_id\"]:\n",
    "        train_folder_listfile[col] = train_folder_listfile[col].astype(int)\n",
    "        test_folder_listfile[col] = test_folder_listfile[col].astype(int)\n",
    "        train_listfile[col] = train_listfile[col].astype(int)\n",
    "        test_listfile[col] = test_listfile[col].astype(int)\n",
    "        val_listfile[col] = val_listfile[col].astype(int)\n",
    "\n",
    "# Save dataframes\n",
    "train_folder_listfile.to_csv(train_folder_listfile_path, index=False)\n",
    "test_folder_listfile.to_csv(test_folder_listfile_path, index=False)\n",
    "train_listfile.to_csv(train_listfile_path, index=False)\n",
    "test_listfile.to_csv(test_listfile_path, index=False)\n",
    "val_listfile.to_csv(val_listfile_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e26288d",
   "metadata": {},
   "source": [
    "## Build new splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246151d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7af75f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base output folder\n",
    "input_folder = \"/data/wolf6245/src/MedFuse/mimic4extract/data/phenotyping\"\n",
    "output_folder = \"/data/wolf6245/src/MedFuse/mimic4extract/data\"\n",
    "\n",
    "# Load all dataframes\n",
    "train_folder_listfile = pd.read_csv(train_folder_listfile_path)\n",
    "test_folder_listfile = pd.read_csv(test_folder_listfile_path)\n",
    "train_listfile = pd.read_csv(train_listfile_path)\n",
    "test_listfile = pd.read_csv(test_listfile_path)\n",
    "val_listfile = pd.read_csv(val_listfile_path)\n",
    "assert train_folder_listfile.shape[0] + test_folder_listfile.shape[0] == train_listfile.shape[0] + test_listfile.shape[0] + val_listfile.shape[0]\n",
    "assert train_folder_listfile.shape[0] == train_listfile.shape[0] + val_listfile.shape[0]\n",
    "\n",
    "# Combine dataframes\n",
    "train_test_folder_listfile = pd.concat([train_folder_listfile, test_folder_listfile], ignore_index=True)\n",
    "train_test_val_listfile = pd.concat([train_listfile, test_listfile, val_listfile], ignore_index=True)\n",
    "assert train_test_folder_listfile.shape[0] == train_test_val_listfile.shape[0], \"train_test_folder_listfile and train_test_val_listfile have different number of rows\"\n",
    "\n",
    "# Get all filepaths\n",
    "all_files = os.listdir(f\"{input_folder}/train/\")\n",
    "all_files += os.listdir(f\"{input_folder}/test/\")\n",
    "all_files = [f for f in all_files if \"listfile\" not in f]\n",
    "#assert len(all_files) == train_test_folder_listfile.shape[0], f\"Number of files and number of rows in train_test_folder_listfile do not match: {len(all_files)} != {train_test_folder_listfile.shape[0]}\"\n",
    "\n",
    "# Get all stays\n",
    "all_stays = list(train_listfile.stay) + list(test_listfile.stay) + list(val_listfile.stay)\n",
    "assert len(all_stays) == len(set(all_stays)), \"Stays are not unique across train, test and val sets\"\n",
    "assert train_folder_listfile.shape[0] + test_folder_listfile.shape[0] == len(all_stays), \"Stays are not unique across train_folder_listfile and test_folder_listfile\"\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(all_stays)\n",
    "n_folds = 5\n",
    "fold_size = len(all_stays) // n_folds\n",
    "folds = {}\n",
    "for i in range(n_folds):\n",
    "    start = i * fold_size\n",
    "    end = (i + 1) * fold_size if i < n_folds - 1 else len(all_stays)\n",
    "    test_stays = all_stays[start:end]\n",
    "    train_stays_full = all_stays[:start] + all_stays[end:]\n",
    "\n",
    "    # Split train_stays_full into train (80%) and val (20%)\n",
    "    val_size = int(0.2 * len(train_stays_full))\n",
    "    val_stays = train_stays_full[:val_size]\n",
    "    train_stays = train_stays_full[val_size:]\n",
    "    folds[i] = {\n",
    "        \"train\": train_stays,\n",
    "        \"test\": test_stays,\n",
    "        \"val\": val_stays\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abcce706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 saved to /data/wolf6245/src/MedFuse/mimic4extract/data/fold_0/phenotyping\n",
      "Fold 0 copied 3637 train files and 909 test files\n",
      "Fold 1 saved to /data/wolf6245/src/MedFuse/mimic4extract/data/fold_1/phenotyping\n",
      "Fold 1 copied 3637 train files and 909 test files\n",
      "Fold 2 saved to /data/wolf6245/src/MedFuse/mimic4extract/data/fold_2/phenotyping\n",
      "Fold 2 copied 3637 train files and 909 test files\n",
      "Fold 3 saved to /data/wolf6245/src/MedFuse/mimic4extract/data/fold_3/phenotyping\n",
      "Fold 3 copied 3637 train files and 909 test files\n",
      "Fold 4 saved to /data/wolf6245/src/MedFuse/mimic4extract/data/fold_4/phenotyping\n",
      "Fold 4 copied 3636 train files and 910 test files\n"
     ]
    }
   ],
   "source": [
    "# Create new dataframes for each fold\n",
    "for i in range(n_folds):\n",
    "    train_stays = folds[i][\"train\"]\n",
    "    test_stays = folds[i][\"test\"]\n",
    "    val_stays = folds[i][\"val\"]\n",
    "    train_val_stays = train_stays + val_stays\n",
    "\n",
    "    # Filter dataframes\n",
    "    train_folder_listfile_fold = train_test_folder_listfile[train_test_folder_listfile.stay.isin(train_val_stays)].copy()\n",
    "    test_folder_listfile_fold = train_test_folder_listfile[train_test_folder_listfile.stay.isin(test_stays)].copy()\n",
    "    train_listfile_fold = train_test_val_listfile[train_test_val_listfile.stay.isin(train_stays)].copy()\n",
    "    test_listfile_fold = train_test_val_listfile[train_test_val_listfile.stay.isin(test_stays)].copy()\n",
    "    val_listfile_fold = train_test_val_listfile[train_test_val_listfile.stay.isin(val_stays)].copy()\n",
    "\n",
    "    # Save dataframes\n",
    "    output_folder_fold = os.path.join(output_folder, f\"fold_{i}/phenotyping\")\n",
    "    train_folder = os.path.join(output_folder_fold, \"train\")\n",
    "    test_folder = os.path.join(output_folder_fold, \"test\")\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "    train_folder_listfile_fold.to_csv(os.path.join(train_folder, \"listfile.csv\"), index=False)\n",
    "    test_folder_listfile_fold.to_csv(os.path.join(test_folder, \"listfile.csv\"), index=False)\n",
    "    train_listfile_fold.to_csv(os.path.join(output_folder_fold, \"train_listfile.csv\"), index=False)\n",
    "    test_listfile_fold.to_csv(os.path.join(output_folder_fold, \"test_listfile.csv\"), index=False)\n",
    "    val_listfile_fold.to_csv(os.path.join(output_folder_fold, \"val_listfile.csv\"), index=False)\n",
    "    print(f\"Fold {i} saved to {output_folder_fold}\")\n",
    "\n",
    "    # Copy files\n",
    "    train_files = train_folder_listfile_fold.stay.tolist()\n",
    "    test_files = test_folder_listfile_fold.stay.tolist()\n",
    "    count_train = 0\n",
    "    count_test = 0\n",
    "    for file in all_files:\n",
    "        if file in train_files:\n",
    "            count_train += 1\n",
    "            os.system(f\"cp {input_folder}/train/{file} {train_folder}/{file}\")\n",
    "        elif file in test_files:\n",
    "            count_test += 1\n",
    "            os.system(f\"cp {input_folder}/test/{file} {test_folder}/{file}\")\n",
    "    print(f\"Fold {i} copied {count_train} train files and {count_test} test files\")\n",
    "    assert count_train == len(train_files), f\"Fold {i} train files do not match: {count_train} != {len(train_files)}\"\n",
    "    assert count_test == len(test_files), f\"Fold {i} test files do not match: {count_test} != {len(test_files)}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f05c3be",
   "metadata": {},
   "source": [
    "## Prep images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8eeebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize\n",
    "## specify the ehr_data_dir and cxr_data_dir directories paths before running the scripts.\n",
    "python resize.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ebd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create image splits\n",
    "python ehr_utils/create_split.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4236cba",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a11373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust\n",
    "src/MedFuse/datasets/fusion.py\n",
    "scripts/radiology/uni_cxr.sh\n",
    "scripts/phenotyping/train/uni_all.sh\n",
    "scripts/phenotyping/train/medFuse.sh\n",
    "scripts/phenotyping/eval/medFuse.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b67c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-train the imaging model with 14 radiology labels.\n",
    "sh ./scripts/radiology/uni_cxr.sh\n",
    "# pre-train LSTM model on extracted time-series EHR data for phenotype task.\n",
    "sh ./scripts/phenotyping/train/uni_all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5fe9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# med fuse for phenotype task\n",
    "sh ./scripts/phenotyping/train/medFuse.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d815b",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4721eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# med fuse for phenotype task\n",
    "sh ./scripts/phenotyping/eval/medFuse.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medfuse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
